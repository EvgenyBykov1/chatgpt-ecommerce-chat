{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¬ Chat-Commerce ðŸ›’"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "%pip install --upgrade python-dotenv langchain chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment values\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Turn off unwanted logs\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index E-Commerce Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = CSVLoader('./data/home-and-garden.csv', csv_args={})\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(documents, embeddings, persist_directory=\"./index/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a shopping assistant that helps visitors find the right product from the store.\n",
    "If you can't find the answer from the context, ask more question. Do not make\n",
    "Once you have an answer, list down the products in a clear tone as markdown list.\n",
    "----------------\n",
    "{context}\"\"\",\n",
    "    input_variables=[\"context\"],\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import VectorDBQA\n",
    "from langchain.agents import Tool\n",
    "\n",
    "product_search = VectorDBQA.from_chain_type(\n",
    "    llm=chat, chain_type=\"stuff\", vectorstore=docsearch\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Product Search\",\n",
    "        func=product_search.run,\n",
    "        description=\"useful for when you need to answer find products available in the store\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prefix_default = \"\"\"\n",
    "Assistant is a large language model trained by OpenAI.\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. \n",
    "As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. \n",
    "Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\"\"\"\n",
    "\n",
    "prefix = \"\"\"\n",
    "You are an AI Shopping Assistant for ShopHome.com, designed to be able to assist the user find the right product in an online store. The store contains products\n",
    "for various categories such as furnitures, home decors, gardening tools and equipments.\n",
    "You are given the following filtered products in a shop and a conversation. You should try better to understand the user needs and suggest one or more products. \n",
    "Provide a conversational answer based on the products provided. If you have more than one product to recommend, show them as bulleted list.\n",
    "If you can't find the answer in the context below, say politely \"Hmm, I'm not sure.\" Don't try to make up a product which is not.\n",
    "\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "ask_ai = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=chat,\n",
    "    agent=\"chat-conversational-react-description\",\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    prefix=prefix,\n",
    "    input_variables=[\"input\", \"agent_scratchpad\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_ai.run(\"Hey! Can you help me to setup my garden?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_ai.run(\"Yes. I need to pots to grow my plants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_ai.run(\"Suggest me a pot which is environmentally friendly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "while True:\n",
    "    request = input(\"Input: \")\n",
    "    IPython.display.display(IPython.display.Markdown(\"User: \" + request))\n",
    "\n",
    "    if request == \"Bye\" or request == \"bye\":\n",
    "        IPython.display.display(IPython.display.Markdown(\"Bot: Bye!\"))\n",
    "        break\n",
    "    else:\n",
    "        response = ask_ai.run(request)\n",
    "        IPython.display.display(IPython.display.Markdown(\"Bot: \" + response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
