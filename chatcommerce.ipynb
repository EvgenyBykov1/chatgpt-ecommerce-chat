{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¬ Chat-Commerce ðŸ›’"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "%pip install python-dotenv langchain chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment values\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Turn off unwanted logs\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index E-Commerce Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "DEBUG:Chroma:Logger created\n",
      "Logger created\n",
      "INFO:clickhouse_connect.driver.ctypes:Successfully imported ClickHouse Connect C data optimizations\n",
      "Successfully imported ClickHouse Connect C data optimizations\n",
      "INFO:clickhouse_connect.driver.ctypes:Successfully import ClickHouse Connect C/Numpy optimizations\n",
      "Successfully import ClickHouse Connect C/Numpy optimizations\n",
      "INFO:clickhouse_connect.json_impl:Using python library for writing JSON byte strings\n",
      "Using python library for writing JSON byte strings\n",
      "loaded in 80 embeddings\n",
      "loaded in 1 collections\n",
      "collection with name langchain already exists, returning existing collection\n",
      "DEBUG:Chroma:Index saved to ./index//index/index.bin\n",
      "Index saved to ./index//index/index.bin\n",
      "Persisting DB to disk, putting it in the save folder ./index/\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = CSVLoader('./data/home-and-garden.csv', csv_args={\n",
    "    \n",
    "})\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(documents, embeddings, persist_directory=\"./index/\")\n",
    "docsearch.persist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a shopping assistant that helps visitors find the right product from the store.\n",
    "If you can't find the answer from the context, ask more question. Do not make\n",
    "Once you have an answer, list down the products in a clear tone as markdown list.\n",
    "----------------\n",
    "{context}\"\"\",\n",
    "    input_variables=[\"context\"],\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ChatVectorDBChain\n",
    "\n",
    "qa = ChatVectorDBChain.from_llm(\n",
    "    llm=chat,\n",
    "    vectorstore=docsearch,\n",
    "    qa_prompt=chat_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def ask(query):\n",
    "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "    chat_history.append((query, result[\"answer\"]))\n",
    "    IPython.display.display(IPython.display.Markdown(result[\"answer\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 1.1920928955078125e-06\n",
      "time to pre process our knn query: 1.1920928955078125e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.00046062469482421875\n",
      "time to run knn query: 0.00046062469482421875\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Of course! What specifically are you looking for? Do you need tools, decorations, or plants?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"Hey! Can you help me find something for my garden?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 3.0994415283203125e-06\n",
      "time to pre process our knn query: 3.0994415283203125e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0005080699920654297\n",
      "time to run knn query: 0.0005080699920654297\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm not looking for any specific pots, I just provided the information for a white ceramic pot. Is there a particular type of pot you are interested in?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"I'm looking for pots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 2.1457672119140625e-06\n",
      "time to pre process our knn query: 2.1457672119140625e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.000492095947265625\n",
      "time to run knn query: 0.000492095947265625\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure! We have biodegradable cardboard pots from Rustic LTD that are perfect for outdoor gardening. They are eco-friendly and will naturally decompose over time, making them a great choice for the environment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"Suggest me a pot which is environmentally friendly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 5.0067901611328125e-06\n",
      "time to pre process our knn query: 5.0067901611328125e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0005028247833251953\n",
      "time to run knn query: 0.0005028247833251953\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure, here are some other environmentally friendly pot options:\n",
       "\n",
       "- Terracotta pots\n",
       "- Ceramic pots\n",
       "- Coconut coir pots\n",
       "- Peat pots\n",
       "- Fabric pots\n",
       "- Glass pots\n",
       "- Metal pots (such as copper or stainless steel)\n",
       "- Wood pots (such as bamboo or cedar)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"yes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
